{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "taken-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pruneshift.networks import create_network\n",
    "from pruneshift.datamodules import ShiftDataModule\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "from pruneshift.losses import ActivationCollector\n",
    "from pruneshift.network_markers import classifier\n",
    "import pytorch_lightning as pl\n",
    "import submitit\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "\n",
    "\n",
    "model_path = Path(\"/work/dlclarge2/hoffmaja-pruneshift/models/\")\n",
    "dataset_path = Path(\"/work/dlclarge2/hoffmaja-pruneshift/datasets/\")\n",
    "activation_path = Path(\"/work/dlclarge2/hoffmaja-pruneshift/activations/\")\n",
    "img100_path = dataset_path / \"ILSVRC2012-100\"\n",
    "img100_train_path = img100_path / \"train\"\n",
    "deepaugment_path = \"/data/datasets/DeepAugment\"\n",
    "# data_amda_path = model_path / \"/imagenetr_models/deepaugment_and_augmix.pth.tar\"\n",
    "data_swsl_path = activation_path / \"img100_swsl_resnet50.npy\"\n",
    "data_amda_path = activation_path / \"img100_amda_resnet50.npy\"\n",
    "data_std_path = activation_path / \"img100_std_resnet50.npy\"\n",
    "\n",
    "amda_path = model_path / \"imagenetr_models/augmix.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "exposed-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTRESTING_NETS = {\n",
    "    \"ResNet18\": \"/work/dlclarge2/hoffmaja-pruneshift/experiments/img100/workshop/baselines/1times_amda/0/checkpoint/last.ckpt\",\n",
    "    \"KD_ResNet18\": \"/work/dlclarge2/agnihotr-shashank-pruneshift/hoffmaja-pruneshift/experiments/img100/workshop/amda_distillation/0/checkpoint/last.ckpt\",\n",
    "    \"AT_ResNet18\": \"/work/dlclarge2/hoffmaja-pruneshift/experiments/img100/workshop/tryout_at/1/checkpoint/last.ckpt\",\n",
    "    \"CRD_ResNet18\": \"/work/dlclarge2/agnihotr-shashank-pruneshift/hoffmaja-pruneshift/shashank_runs/imagenet100_runs/amda_teacher_amda_student_crd/crd_1.0/kd_1.0/checkpoint/last.ckpt\",\n",
    "    \"SupCon_kd_augmix\": \"/work/dlclarge2/agnihotr-shashank-pruneshift/runs_supcon/imagenet100_again/kd_augmix/classification_amda/checkpoint/last.ckpt\",\n",
    "    \"SupCon_augmix\" : \"/work/dlclarge2/agnihotr-shashank-pruneshift/runs_supcon/imagenet100_again/augmix/classification_amda/checkpoint/last.ckpt\"}\n",
    "\n",
    "#\"Amda_ResNet50\": \"/work/dlclarge2/hoffmaja-pruneshift/models/imagenetr_models/deepaugment_and_augmix.pth.tar\",\n",
    "def create_executor(folder, num_gpus):\n",
    "    executor = submitit.AutoExecutor(folder=folder)\n",
    "    executor.update_parameters(nodes=1,\n",
    "                               gpus_per_node=num_gpus,\n",
    "                               slurm_partition=\"lmbdlc_gpu-rtx2080\",\n",
    "                               slurm_array_parallelism=35,\n",
    "                               timeout_min=100)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "macro-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODES = [\"amda\", \"test\", \"renditions\", \"corrupted\"]\n",
    "TEST_MODES = MODES[-3:]\n",
    "\n",
    "def dataloaders(mode: str, batch_size: int):\n",
    "    assert mode in MODES\n",
    "    \n",
    "    kws = {}\n",
    "    kws[\"test_renditions\"] = True if mode == \"renditions\" else False\n",
    "    kws[\"test_corrupted\"] = True if mode == \"corrupted\" else False\n",
    "    kws[\"augmix\"] = \"no_jsd\" if mode == \"augmix\" or mode == \"amda\" else False\n",
    "    kws[\"deepaugment_path\"] = deepaugment_path if mode == \"deepaugment\" or mode == \"amda\" else None\n",
    "        \n",
    "    dm = ShiftDataModule(\"imagenet\", img100_path, batch_size=batch_size, **kws)\n",
    "    \n",
    "    if mode in TEST_MODES:\n",
    "        dm.setup(\"test\")\n",
    "        \n",
    "        if mode == \"test\":\n",
    "            dataset = dm.test_datasets[0]\n",
    "        elif mode == \"renditions\":\n",
    "            dataset = dm.test_datasets[1]\n",
    "        else:\n",
    "            dataset = ConcatDataset(dm.test_datasets[1 :])\n",
    "            \n",
    "        return DataLoader(dataset, batch_size, True, num_workers=2)\n",
    "    \n",
    "    dm.setup(\"fit\")\n",
    "    return dm.train_dataloader()\n",
    "        \n",
    "\n",
    "\n",
    "def collect_samples(network_name,\n",
    "                    network_path,\n",
    "                    mode: str,\n",
    "                    with_logits: bool = True,\n",
    "                    with_features: bool = True,\n",
    "                    num_samples: int = 256,\n",
    "                    batch_size: int = 256):\n",
    "    \"\"\" Makes some forward passes on ImageNet100\"\"\" #, imagenet_subset_path=img100_path, imagnet_path=img100_train_path\n",
    "    if '50' in network_name:\n",
    "        net = create_network(\"imagenet\", \"resnet50\", 100, ckpt_path=network_path)\n",
    "    elif 'SupCon' in network_name:\n",
    "        net = create_network(\"imagenet\", \"resnet18\", 100, ckpt_path=network_path, supConLoss=True, classifying=True, loading_final_supcon=True)\n",
    "    else:\n",
    "        net = create_network(\"imagenet\", \"resnet18\", 100, ckpt_path=network_path)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print(\"Create datamodule.\")\n",
    "\n",
    "    loader = dataloaders(mode, batch_size)\n",
    "\n",
    "    num_samples = num_samples // batch_size\n",
    "    collector = ActivationCollector({\"fc\": classifier(net)}, mode=\"in\")\n",
    "\n",
    "    net = net.to(device)\n",
    "    # Meta Information\n",
    "    info = defaultdict(list)\n",
    "    # Logits and Activations\n",
    "    # data = defaultdict(list)\n",
    "\n",
    "    for _, batch in tqdm(zip(range(num_samples), loader)):\n",
    "        _, x, y = batch\n",
    "        x = x.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_batch = net(x)\n",
    "\n",
    "        for label, activations, logits in zip(y, collector[\"fc\"], logits_batch):\n",
    "            # if train\n",
    "            \n",
    "            info[\"Class Idx\"].append(label.item())\n",
    "            info[\"Network Name\"].append(network_name)\n",
    "            info[\"Distribution\"].append(mode)\n",
    "            info[\"Logits\"].append(logits.cpu().numpy())\n",
    "            info[\"Features\"].append(activations.cpu().numpy())\n",
    "\n",
    "        collector.reset()\n",
    "\n",
    "    df_info = pd.DataFrame(info)\n",
    "    # df_info.columns = pd.MultiIndex.from_product([[\"Info\"], df_info.columns])\n",
    "    return df_info\n",
    "    \n",
    "    num_logits = 100\n",
    "    num_features = data[\"Features\"][0].shape[-1]\n",
    "\n",
    "    df_logits = pd.DataFrame(np.stack(data[\"Logits\"]))\n",
    "    df_logits.columns = pd.MultiIndex.from_product([[\"Logits\"], range(num_logits)])\n",
    "    df_features = pd.DataFrame(np.stack(data[\"Features\"]))\n",
    "    df_features.columns = pd.MultiIndex.from_product([[\"Features\"], range(num_features)])\n",
    "\n",
    "    df_parts = [df_info]\n",
    "    \n",
    "    if with_features:\n",
    "        df_parts.append(df_logits)\n",
    "    \n",
    "    if with_logits:\n",
    "        df_parts.append(df_features)\n",
    "    \n",
    "    return pd.concat([df_info, df_logits, df_features], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "correct-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to sweep over augmix and deepaugment, train, test\n",
    "def sweep(**kws):\n",
    "    executor = create_executor(\"./submitit_runs\", 1)\n",
    "    names = list(INTRESTING_NETS.keys())\n",
    "    paths = [INTRESTING_NETS[n] for n in INTRESTING_NETS]\n",
    "\n",
    "    jobs = []\n",
    "    with executor.batch():\n",
    "        for mode in MODES:\n",
    "            for name, path in INTRESTING_NETS.items():\n",
    "                job = executor.submit(collect_samples, name, path, mode, **kws)\n",
    "                jobs.append(job)\n",
    "\n",
    "    return pd.concat([j.result() for j in jobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-valuation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "potential-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sweep(num_samples=256*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "animated-making",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2522832 ,  8.020609  ,  3.7160256 ,  1.5858282 , -0.6066107 ,\n",
       "       -1.8614795 , -2.0555408 ,  1.303268  ,  4.309605  ,  1.9008783 ,\n",
       "       -2.6020973 ,  0.11717378, -2.502744  ,  0.05916312, -2.641747  ,\n",
       "       -1.3596619 , -1.8055562 , -0.8236914 , -2.0011315 ,  0.22227022,\n",
       "       -3.303973  , -0.3437702 , -2.0403488 ,  1.5712047 ,  4.6484623 ,\n",
       "        3.1017349 , -2.068096  , -0.8709048 ,  0.46873292, -2.2186825 ,\n",
       "       -1.4154774 ,  0.14736672,  3.058052  ,  5.0133076 ,  4.577844  ,\n",
       "       12.068056  , 14.700689  ,  5.826222  , -0.26689857, -0.11844517,\n",
       "       -0.50574195, -0.71693957, -0.38355532, -1.1683133 , -0.5376086 ,\n",
       "       -0.77848536, -0.2509188 , -1.7561966 ,  0.976316  , -0.07694538,\n",
       "        1.6302834 , -0.4737046 ,  0.66315603, -0.24893896,  0.19256271,\n",
       "        1.659791  , -1.0942785 , -0.4849017 , -0.27781862,  0.49353683,\n",
       "        0.33059588,  1.029828  , -0.58503395, -1.1760771 , -0.69789886,\n",
       "       -0.60041296, -0.17096189, -0.3012425 ,  0.92729354, -0.49912453,\n",
       "       -1.6267134 , -0.35695454, -0.08915396, -1.9790734 , -2.27286   ,\n",
       "       -1.66347   , -2.5777974 , -2.8239462 ,  2.3659182 , -3.000734  ,\n",
       "       -2.0857382 , -2.0291495 , -3.569761  , -1.7250521 , -1.2522402 ,\n",
       "       -1.1358542 , -1.1344285 , -2.1031246 , -4.592905  ,  1.0614265 ,\n",
       "       -0.8485858 , -0.02986822, -2.015941  ,  0.24117352, -0.15085673,\n",
       "       -2.4501545 ,  0.32839602,  1.3107475 , -0.9083427 , -2.1636155 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Logits\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "british-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"supcon_analysis.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "specific-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"std.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "funky-vertex",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feather does not support serializing a non-default index for the index; you can .reset_index() to make the index into column(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-192f577ebe9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"short_features_logits.bird\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/dlclarge2/hoffmaja-pruneshift/envs/pruneshift/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/dlclarge2/hoffmaja-pruneshift/envs/pruneshift/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_feather\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m   2289\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeather_format\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_feather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2291\u001b[0;31m         \u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m     @doc(\n",
      "\u001b[0;32m/work/dlclarge2/hoffmaja-pruneshift/envs/pruneshift/lib/python3.8/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mto_feather\u001b[0;34m(df, path, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRangeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;34m\"feather does not support serializing a non-default index for the index; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;34m\"you can .reset_index() to make the index into column(s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feather does not support serializing a non-default index for the index; you can .reset_index() to make the index into column(s)"
     ]
    }
   ],
   "source": [
    "df.to_feather(\"short_features_logits.bird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "worst-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = executor.submit(collect_samples, amda_path, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "matched-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cellular-norwegian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Idx</th>\n",
       "      <th>DeepAugment</th>\n",
       "      <th>Augmix</th>\n",
       "      <th>Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>93</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class Idx  DeepAugment  Augmix  Train\n",
       "0           33        False   False   True\n",
       "1           60        False   False   True\n",
       "2           42        False   False   True\n",
       "3           42        False   False   True\n",
       "4           74        False   False   True\n",
       "..         ...          ...     ...    ...\n",
       "763         40        False   False   True\n",
       "764         98        False   False   True\n",
       "765         93        False   False   True\n",
       "766         81        False   False   True\n",
       "767         95        False   False   True\n",
       "\n",
       "[768 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = create_executor(\"./test_runs\", 1)\n",
    "jobs = executor.map_array(collect_samples, paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
