{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46995377-27ab-4e2e-87f2-edc1d71cf90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "# 1. prune seperate    .......................done\n",
    "# 2. calibrated pruned seperate ..............done\n",
    "# 3. prune joint train seperate   ............done\n",
    "# 4. calibrated prune joint train seperate ....done\n",
    "# 5. prune and train joint     ................done\n",
    "# 6. calibrated prune and train joint    .....missing\n",
    "# 7. Scaled up resnet18     ..................\n",
    "# 8. Calibrated scaled up resnet18   .........\n",
    "# 9. Multiheaded  ............................\n",
    "\n",
    "# 1. Compare errors, test error, ECE, mCE, Rendition\n",
    "# 2. What layers are being pruned\n",
    "# 3. What is the network predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8675d4-accc-4a58-902d-e5b72501ab1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbd9014-aa26-407d-981c-44961a1f1015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:471: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf, \"prune\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:494: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"ensemble\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:539: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"multiheaded\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:547: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf, \"teacher\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:550: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"scaling_factor\"):\n",
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/snow\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/shot_noise\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/scale\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/gaussian_noise\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/tilt\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/motion_blur\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/brightness\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/rotate\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/zoom_blur\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/translate\n",
      "error:  tensor(0.2242, device='cuda:0')\n",
      "mFR:  0.05124050000000009\n",
      "mECE:  tensor(0.1235)\n",
      "ece:  tensor(1.5870)\n",
      "err:  tensor(0.1799)\n",
      "mCE:  tensor(0.5994)\n"
     ]
    }
   ],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "alexnet=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/alexnet_pretrained\"))\n",
    "add_info(alexnet)\n",
    "#alexnet = alexnet.sort_values(by=\"Model Size\")\n",
    "alexnet.to_csv('csv/alexnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ffc0b-08ce-4044-96ff-405f10a4be65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c5c4f-4ee2-47f2-8418-48c439f33e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00c24c-a3fc-4969-b911-dc90d1b6969d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc67ef2b-9c33-4377-a927-07fa07c5fba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:471: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf, \"prune\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:472: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  value = OmegaConf.is_none(conf, \"prune\")\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:494: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"ensemble\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:539: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"multiheaded\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:547: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf, \"teacher\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:550: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"scaling_factor\"):\n",
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/snow\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.55 GiB (GPU 0; 11.93 GiB total capacity; 3.57 GiB already allocated; 2.28 GiB free; 8.88 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2646306/1057959645.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m      Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/scaled_resnet18/imagenet100/pruned/l1_global/standard\")]\n\u001b[1;32m     13\u001b[0m \u001b[0mscaled_up_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0madd_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_up_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mscaled_up_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_up_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Model Size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mscaled_up_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Not Calibrated Scaled Up\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not Calibrated Scaled Up\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not Calibrated Scaled Up\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not Calibrated Scaled Up\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not Calibrated Scaled Up\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not Calibrated Scaled Up\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py\u001b[0m in \u001b[0;36madd_info\u001b[0;34m(df, num_workers)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Path\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Scaling\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Network\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ensemble\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loading_ensemble\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiheaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"network1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"network2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"network3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m#print(row)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mece_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml4_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_ece_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_err_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_flip_prob_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_ece_per_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_err_per_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mece_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py\u001b[0m in \u001b[0;36madd_ece\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mmean_flip_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_ece_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_err_per\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_on_per\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multiheaded\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_ece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multiheaded\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mmean_ece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_ece_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multiheaded\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/test.py\u001b[0m in \u001b[0;36mcalculate_on_per\u001b[0;34m(net, multiheaded)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmultiheaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/env/hiwi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/agnihotr-ensemble/pruneshift/src/scalable_resnet/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/agnihotr-ensemble/pruneshift/src/scalable_resnet/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/env/hiwi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/env/hiwi/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/lmbraid19/agnihotr/env/hiwi/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2147\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.55 GiB (GPU 0; 11.93 GiB total capacity; 3.57 GiB already allocated; 2.28 GiB free; 8.88 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "path=[Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/scaled_resnet18/imagenet100/standard_1.73\"), \n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/scaled_resnet18/imagenet100/pruned/l1_global/standard\")]\n",
    "scaled_up_std=collect(*path)\n",
    "add_info(scaled_up_std)\n",
    "scaled_up_std = scaled_up_std.sort_values(by=\"Model Size\")\n",
    "scaled_up_std[\"Name\"]=[\"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\"]\n",
    "scaled_up_std.to_csv('csv/scaled_up_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83386503-90b8-4d5d-86c1-08d05062113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8294f0-fd73-4e4d-af00-0ea38f8a5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "path=[Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/scaled_resnet18/imagenet100/amda_1.73\"), \n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/scaled_resnet18/imagenet100/pruned/l1_global/amda\")]\n",
    "scaled_up_amda=collect(*path)\n",
    "add_info(scaled_up_amda)\n",
    "scaled_up_amda = scaled_up_amda.sort_values(by=\"Model Size\")\n",
    "scaled_up_amda[\"Name\"]=[\"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\", \"Not Calibrated Scaled Up\"]\n",
    "scaled_up_amda.to_csv('csv/scaled_up_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d1d49-a2bb-48b4-b1e5-e3710dccb5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97f803-c5a3-4aba-89ed-ea2b74843c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "path=Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/calibrated_scaled_up/resnet18/amda\")\n",
    "calibrated_scaled_up_amda=collect(path)\n",
    "add_info(calibrated_scaled_up_amda)\n",
    "calibrated_scaled_up_amda = calibrated_scaled_up_amda.sort_values(by=\"Model Size\")\n",
    "calibrated_scaled_up_amda[\"Name\"]=[\"Calibrated Scaled Up\", \"Calibrated Scaled Up\", \"Calibrated Scaled Up\", \"Calibrated Scaled Up\", \"Calibrated Scaled Up\", \"Calibrated Scaled Up\"]\n",
    "calibrated_scaled_up_amda.to_csv('csv/calibrated_scaled_up_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329f0ed-d667-472e-b1eb-bca12914c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace466c-a188-486a-bb87-dfb6e75d590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "path=Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/calibrated_scaled_up/resnet18/standard\")\n",
    "calibrated_scaled_up_std=collect(path)\n",
    "add_info(calibrated_scaled_up_std)\n",
    "calibrated_scaled_up_std = calibrated_scaled_up_std.sort_values(by=\"Model Size\")\n",
    "calibrated_scaled_up_std[\"Name\"]=[\"Calibrated Scaled Up\", \"Calibrated Scaled Up\", \"Calibrated Scaled Up\", \"Calibrated Scaled Up\", \"Calibrated Scaled Up\", \"Calibrated Scaled Up\"]\n",
    "calibrated_scaled_up_std.to_csv('csv/calibrated_scaled_up_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e247449c-ccc8-46c0-b160-852f7245be20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.lab.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c3140-6009-446f-bf8f-94fb672435ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a015c5b2-9c60-4b8f-9f4f-c6b919de834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "cuda = torch.device('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3aa21f-7693-4147-940d-426edd5b22ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:470: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf, \"prune\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:493: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"ensemble\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:495: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"loading_ensemble\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:520: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(parent_conf, \"prune\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:538: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"multiheaded\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:546: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf, \"teacher\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:549: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"scaling_factor\"):\n",
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ece:  tensor(1.5371)\n",
      "err:  tensor(0.1079)\n",
      "mCE:  tensor(0.2548)\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/snow\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/shot_noise\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/scale\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/gaussian_noise\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/tilt\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/motion_blur\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/brightness\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/rotate\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/zoom_blur\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/translate\n",
      "error:  tensor(0.1229, device='cuda:0')\n",
      "mFR:  0.016523333333333366\n",
      "mECE:  tensor(0.0444)\n"
     ]
    }
   ],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "seperate_amda_base=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_ensembles/resnet18/amda/performance\"))\n",
    "add_info(seperate_amda_base)\n",
    "seperate_amda_base = seperate_amda_base.sort_values(by=\"Model Size\")\n",
    "seperate_amda_base.to_csv('csv/seperate_amda_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ab2f48-3738-461a-b928-70fb7ca2f329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.lab.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bda8c-e4dd-4bd6-96e8-968269390165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "seperate_std_base=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_ensembles/resnet18/standard/performance\"))\n",
    "add_info(seperate_std_base)\n",
    "seperate_std_base = seperate_std_base.sort_values(by=\"Model Size\")\n",
    "seperate_std_base.to_csv('csv/seperate_std_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11045ba2-f61f-4ae1-b9c4-4e400cc50074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541162cf-44c2-4b9b-a69b-0cfbdbd4fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "seperate_amda_pruned=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_ensembles/resnet18/amda/prune_sep/performance\"))\n",
    "add_info(seperate_amda_pruned)\n",
    "seperate_amda_pruned = seperate_amda_pruned.sort_values(by=\"Model Size\")\n",
    "seperate_amda_pruned.to_csv('csv/seperate_amda_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160cce42-5f26-454f-8463-88263022a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79c480-4acb-4254-b221-895d21081590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "seperate_std_pruned=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_ensembles/resnet18/standard/prune_sep/performance\"))\n",
    "add_info(seperate_std_pruned)\n",
    "seperate_std_pruned = seperate_std_pruned.sort_values(by=\"Model Size\")\n",
    "seperate_std_pruned.to_csv('csv/seperate_std_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207835f6-0d4b-4bee-8410-09f0f0fbbb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f243904-dcd5-4ed5-a500-7ba08798cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_amda_base=pd.read_csv('csv/seperate_amda_base.csv')\n",
    "seperate_amda_base[\"Prune Amount\"]=0\n",
    "seperate_amda_pruned=pd.read_csv('csvs/seperate_amda_pruned.csv')\n",
    "seperate_amda=seperate_amda_base.append(seperate_amda_pruned, ignore_index=True)\n",
    "seperate_amda=seperate_amda.sort_values(by=\"Model Size\")\n",
    "seperate_amda[\"Name\"] = [\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\"]\n",
    "seperate_amda.to_csv('csv/not_calibrated_seperate_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d924040-f296-43fd-b3e6-020d8e2ef6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866c579-8b29-4d3f-8ce9-30adb7c65bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_std_base=pd.read_csv('csv/seperate_std_base.csv')\n",
    "seperate_std_pruned=pd.read_csv('csv/seperate_std_pruned.csv')\n",
    "seperate_std=seperate_std_base.append(seperate_std_pruned, ignore_index=True)\n",
    "seperate_std=seperate_std.sort_values(by=\"Model Size\")\n",
    "seperate_std[\"Name\"] = [\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\",\"Not Calibrated Prune-Train seperate\"]\n",
    "seperate_std.to_csv('csv/not_calibrated_seperate_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d5096-61eb-455b-ba7e-2d7740716e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ace9e6-1f94-4277-b60c-75d8a76b3345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e5739-16eb-4b57-bb78-21b8e03a9d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a70e3-de0f-4dd1-a526-1d8683f58e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "path=[Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/standard/finetuned/10/performance\"), \n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/standard/finetuned/25/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/standard/finetuned/50/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/standard/finetuned/70/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/standard/finetuned/90/performance\")]\n",
    "pruned_jointly_std_pruned=collect(*path)\n",
    "add_info(pruned_jointly_std_pruned)\n",
    "pruned_jointly_std_pruned = pruned_jointly_std_pruned.sort_values(by=\"Model Size\")\n",
    "pruned_jointly_std_pruned.to_csv('csv/not_calibrated_pruned_jointly_std_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b1d46-5a5a-408f-900c-216c11cba7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f6ea8e-25d1-4a90-a258-7b5c676d977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "path=[Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/amda/finetuned/10/performance\"), \n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/amda/finetuned/25/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/amda/finetuned/50/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/amda/finetuned/70/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/not_calibrated/amda/finetuned/90/performance\")]\n",
    "pruned_jointly_amda_pruned=collect(*path)\n",
    "add_info(pruned_jointly_amda_pruned)\n",
    "pruned_jointly_amda_pruned = pruned_jointly_amda_pruned.sort_values(by=\"Model Size\")\n",
    "pruned_jointly_amda_pruned.to_csv('csv/not_calibrated_pruned_jointly_amda_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f31ce-8072-4ff8-98ab-929f7266c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763fae61-e393-4410-9081-a699fc797fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_std_base=pd.read_csv('csv/seperate_std_base.csv')\n",
    "pruned_jointly_std_pruned=pd.read_csv('csv/not_calibrated_pruned_jointly_std_pruned.csv')\n",
    "pruned_jointly_std=seperate_std_base.append(pruned_jointly_std_pruned, ignore_index=True)\n",
    "pruned_jointly_std=pruned_jointly_std.sort_values(by=\"Model Size\")\n",
    "pruned_jointly_std[\"Name\"] = [\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\"]\n",
    "pruned_jointly_std.to_csv('csv/not_calibrated_pruned_jointly_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f67c6-9357-4f1c-a89e-6ec8585e3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61cb65-a336-4f0d-91fd-9baacebb4d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07463a18-f281-45d9-a9e3-0ae7a0f10ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_amda_base=pd.read_csv('csv/seperate_amda_base.csv')\n",
    "pruned_jointly_amda_pruned=pd.read_csv('csv/not_calibrated_pruned_jointly_amda_pruned.csv')\n",
    "pruned_jointly_amda=seperate_amda_base.append(pruned_jointly_amda_pruned, ignore_index=True)\n",
    "pruned_jointly_amda=pruned_jointly_amda.sort_values(by=\"Model Size\")\n",
    "pruned_jointly_amda[\"Name\"] = [\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\",\"Not Calibrated Prune joint Train seperate\"]\n",
    "pruned_jointly_amda.to_csv('csv/not_calibrated_pruned_jointly_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cce144-bacb-41bb-a966-0cc683121ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b762210-4dce-4d55-9355-69c8af558595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51364843-89bb-4613-888d-4e3d9410fccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e3859-deeb-4b24-894a-4686054bf7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bd469-ee6f-4605-b557-f846d2be3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "path=[Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/standard/finetuned/10/performance\"), \n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/standard/finetuned/25/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/standard/finetuned/50/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/standard/finetuned/70/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/standard/finetuned/90/performance\")]\n",
    "calibrated_pruned_jointly_std_pruned=collect(*path)\n",
    "add_info(calibrated_pruned_jointly_std_pruned)\n",
    "calibrated_pruned_jointly_std_pruned = calibrated_pruned_jointly_std_pruned.sort_values(by=\"Model Size\")\n",
    "calibrated_pruned_jointly_std_pruned.to_csv('csv/calibrated_pruned_jointly_std_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d0d41-db2d-4095-89a8-489e93198ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c47d7e-6e3b-4d89-ad42-92ece29a0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "path=[Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/amda/finetuned/10/performance\"), \n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/amda/finetuned/25/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/amda/finetuned/50/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/amda/finetuned/70/performance\"),\n",
    "     Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/second_prune_joint_train_sep/calibrated/amda/finetuned/90/performance\")]\n",
    "calibrated_pruned_jointly_amda_pruned=collect(*path)\n",
    "add_info(calibrated_pruned_jointly_amda_pruned)\n",
    "calibrated_pruned_jointly_amda_pruned = calibrated_pruned_jointly_amda_pruned.sort_values(by=\"Model Size\")\n",
    "calibrated_pruned_jointly_amda_pruned.to_csv('csv/calibrated_pruned_jointly_amda_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fbaaf-95eb-4a05-b688-f7ad35296636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b37e06-514f-4dad-ba30-b2467249b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_std_base=pd.read_csv('csv/calibrated_seperate_std_base.csv')\n",
    "calibrated_pruned_jointly_std_pruned=pd.read_csv('csv/calibrated_pruned_jointly_std_pruned.csv')\n",
    "calibrated_pruned_jointly_std=calibrated_seperate_std_base.append(calibrated_pruned_jointly_std_pruned, ignore_index=True)\n",
    "calibrated_pruned_jointly_std=calibrated_pruned_jointly_std.sort_values(by=\"Model Size\")\n",
    "calibrated_pruned_jointly_std[\"Name\"] = [\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\"]\n",
    "calibrated_pruned_jointly_std.to_csv('csv/calibrated_pruned_jointly_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37064bb8-24be-456b-8b8f-ae56c8a97996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a80db9-7d95-4fe6-99ab-b22bd4b35edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_amda_base=pd.read_csv('csv/calibrated_seperate_amda_base.csv')\n",
    "calibrated_pruned_jointly_amda_pruned=pd.read_csv('csv/calibrated_pruned_jointly_amda_pruned.csv')\n",
    "calibrated_pruned_jointly_amda=calibrated_seperate_amda_base.append(calibrated_pruned_jointly_amda_pruned, ignore_index=True)\n",
    "calibrated_pruned_jointly_amda=calibrated_pruned_jointly_amda.sort_values(by=\"Model Size\")\n",
    "calibrated_pruned_jointly_amda[\"Name\"] = [\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\",\"Calibrated Prune joint Train seperate\"]\n",
    "calibrated_pruned_jointly_amda.to_csv('csv/calibrated_pruned_jointly_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd27fe-9c77-4412-87f0-58dec3021f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78facde6-a1d2-4d8a-9c32-69a713643199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5d6e5-9b3f-49cd-8e2c-7cece2e555eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665791ba-0c91-4123-8fe9-0c04267d3bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae4fc7-a070-49d7-a72c-deb716dd2637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_base=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/together_second/resnet18/amda\"))\n",
    "add_info(together_amda_base)\n",
    "together_amda_base = together_amda_base.sort_values(by=\"Model Size\")\n",
    "together_amda_base.to_csv('csv/together_amda_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fca3f-e599-44f3-bd22-bceed9102a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875bfdc-770b-4a91-ae5b-78ee0ab99f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_base=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/together_second/resnet18/standard\"))\n",
    "add_info(together_std_base)\n",
    "together_std_base = together_std_base.sort_values(by=\"Model Size\")\n",
    "together_std_base.to_csv('csv/together_std_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac638d-2096-4d3a-aa59-2d9392675c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53eefe-7ccf-4da5-97f0-e86655348172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749ce6e-bc11-4757-a50a-69851330a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_pruned=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/together_second/resnet18/pruned_amda\"))\n",
    "add_info(together_amda_pruned)\n",
    "together_amda_pruned = together_amda_pruned.sort_values(by=\"Model Size\")\n",
    "together_amda_pruned.to_csv('csv/together_amdfrom IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()a_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891b97b-cf6c-4b11-b6d9-273a8656669f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a68c50-2930-4159-a536-93139bd4fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_pruned=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/together_second/resnet18/pruned_standard\"))\n",
    "add_info(together_std_pruned)\n",
    "together_std_pruned = together_std_pruned.sort_values(by=\"Model Size\")\n",
    "together_std_pruned.to_csv('csv/together_std_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bffc9-cb56-4bc7-87fe-ae29d5320bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1efca5-b006-4589-be58-39cdd82f139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_base=pd.read_csv('csv/together_std_base.csv')\n",
    "together_std_pruned=pd.read_csv('csv/together_std_pruned.csv')\n",
    "together_std=together_std_base.append(together_std_pruned, ignore_index=True)\n",
    "together_std=together_std.sort_values(by=\"Model Size\")\n",
    "together_std[\"Name\"] = [\"Prune-Train jointly\",\"Prune-Train jointly\",\"Prune-Train jointly\",\"Prune-Train jointly\",\"Prune-Train jointly\",\"Prune-Train jointly\"]\n",
    "together_std.to_csv('csv/together_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef56bbd-ac22-48e8-947a-10d9855ce88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da551f73-295c-49fc-9045-b06ce493aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_base=pd.read_csv('csv/together_amda_base.csv')\n",
    "together_amda_pruned=pd.read_csv('csv/together_amda_pruned.csv')\n",
    "together_amda=together_amda_base.append(together_amda_pruned, ignore_index=True)\n",
    "together_amda=together_amda.sort_values(by=\"Model Size\")\n",
    "together_amda[\"Name\"] = [\"Prune-Train jointly\",\"Prune-Train jointly\",\"Prune-Train jointly\",\"Prune-Train jointly\",\"Prune-Train jointly\",\"Prune-Train jointly\"]\n",
    "together_amda.to_csv('csv/together_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6c096-1cc3-4043-b43c-808c3ac3bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c643a5-8d64-4820-a825-2d4ff45f3025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f087ae3-fb12-486e-ac2f-c3f917d1f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_amda_base=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/calibrated/resnet18/amda/unpruned/performance\"))\n",
    "add_info(calibrated_seperate_amda_base)\n",
    "calibrated_seperate_amda_base = calibrated_seperate_amda_base.sort_values(by=\"Model Size\")\n",
    "calibrated_seperate_amda_base.to_csv('csv/calibrated_seperate_amda_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636043d-e062-4d8a-af6e-b4b947e824d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84d642-169c-41e4-bfe9-66e12dc582db",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_std_base=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/calibrated/resnet18/standard/unpruned/performance\"))\n",
    "add_info(calibrated_seperate_std_base)\n",
    "calibrated_seperate_std_base = calibrated_seperate_std_base.sort_values(by=\"Model Size\")\n",
    "calibrated_seperate_std_base.to_csv('csv/calibrated_seperate_std_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3db5e-07bf-4503-9b90-41a384482a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2c05d-b343-437f-8c57-24282bfa8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_amda_pruned=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/calibrated/resnet18/amda/pruned/performance\"))\n",
    "add_info(calibrated_seperate_amda_pruned)\n",
    "calibrated_seperate_amda_pruned = calibrated_seperate_amda_pruned.sort_values(by=\"Model Size\")\n",
    "calibrated_seperate_amda_pruned.to_csv('csv/calibrated_seperate_amda_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02484b-b145-405a-98a2-b672c8cf784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a9bf6-7c19-4364-8f7e-1602cca11f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_std_pruned=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/calibrated/resnet18/standard/pruned/performance\"))\n",
    "add_info(calibrated_seperate_std_pruned)\n",
    "calibrated_seperate_std_pruned = calibrated_seperate_std_pruned.sort_values(by=\"Model Size\")\n",
    "calibrated_seperate_std_pruned.to_csv('csv/calibrated_seperate_std_pruned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264ad7a-f2f0-4869-a884-28c276d9895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a357b-1d35-444c-91ac-766e4b25c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_amda_base=pd.read_csv('csv/calibrated_seperate_amda_base.csv')\n",
    "calibrated_seperate_amda_pruned=pd.read_csv('csv/calibrated_seperate_amda_pruned.csv')\n",
    "calibrated_seperate_amda=calibrated_seperate_amda_base.append(calibrated_seperate_amda_pruned, ignore_index=True)\n",
    "calibrated_seperate_amda=calibrated_seperate_amda.sort_values(by=\"Model Size\")\n",
    "calibrated_seperate_amda[\"Name\"] = [\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\"]\n",
    "calibrated_seperate_amda.to_csv('csv/calibrated_seperate_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28975d72-5f3f-4dd5-9e33-70c5573f0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94c2cc-239b-4f26-bbff-a89b44559224",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_std_base=pd.read_csv('csv/calibrated_seperate_std_base.csv')\n",
    "calibrated_seperate_std_pruned=pd.read_csv('csv/calibrated_seperate_std_pruned.csv')\n",
    "calibrated_seperate_std=calibrated_seperate_std_base.append(calibrated_seperate_std_pruned, ignore_index=True)\n",
    "calibrated_seperate_std=calibrated_seperate_std.sort_values(by=\"Model Size\")\n",
    "calibrated_seperate_std[\"Name\"] = [\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\",\"Calibrated Prune-Train seperate\"]\n",
    "calibrated_seperate_std.to_csv('csv/calibrated_seperate_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d1c02-108e-4552-ab48-960ffcb7e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f652b-d31c-4a49-acf1-34d8844dc15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84669868-c76f-4d91-b1f5-8a2c72e727d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bd9c9-61c6-4c18-9683-d29ea3f8e3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b218334-04e9-4260-907d-790ac0f92add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:471: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf, \"prune\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:494: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"ensemble\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:539: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"multiheaded\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:547: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf, \"teacher\"):\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:550: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if not OmegaConf.is_none(conf.network, \"scaling_factor\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/snow\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/shot_noise\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/scale\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/gaussian_noise\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/tilt\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/motion_blur\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/brightness\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/rotate\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/zoom_blur\n",
      "/misc/lmbraid19/agnihotr/datasets/ImageNet-100-P/translate\n",
      "error:  tensor(0.1474, device='cuda:0')\n",
      "mFR:  0.0364855\n",
      "mECE:  tensor(0.0950)\n",
      "ece:  tensor(1.2599)\n",
      "err:  tensor(0.1170)\n",
      "mCE:  tensor(0.5102)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ECE\"]=ece\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"err\"]=err\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:289: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"mean ECE corr\"]=mean_ece\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"mCE calc\"] = mean_err\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:291: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"mFP\"] = mean_flip_prob\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:292: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"mean ECE pertubation\"]= mean_ece_per\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"mean error pertubation\"] = mean_err_per\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:294: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Layer1 Remaining\"]=l1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Layer2 Remaining\"]=l2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Layer3 Remaining\"]=l3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Layer4 Remaining\"]=l4\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Test Class 1 Probability\"]=p_test_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:300: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Test Class 1 Name\"]=class_test_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Test Class 2 Probability\"]=p_test_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:302: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Test Class 2 Name\"]=class_test_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Test Class 3 Probability\"]=p_test_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Test Class 3 Name\"]=class_test_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:305: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Test Target Probability\"]=p_target_test\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:306: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Test Target Name\"]=class_target_test\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 1 Class 1 Probability\"]=p_b1_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 1 Class 1 Name\"]=class_b1_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:310: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 1 Class 2 Probability\"]=p_b1_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 1 Class 2 Name\"]=class_b1_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:312: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 1 Class 3 Probability\"]=p_b1_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 1 Class 3 Name\"]=class_b1_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:314: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 1 Target Probability\"]=p_target_b1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 1 Target Name\"]=class_target_b1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:318: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 3 Class 1 Probability\"]=p_b3_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:319: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 3 Class 1 Name\"]=class_b3_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:320: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 3 Class 2 Probability\"]=p_b3_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:321: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 3 Class 2 Name\"]=class_b3_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 3 Class 3 Probability\"]=p_b3_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:323: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 3 Class 3 Name\"]=class_b3_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 3 Target Probability\"]=p_target_b3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:325: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 3 Target Name\"]=class_target_b3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:328: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 5 Class 1 Probability\"]=p_b5_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:329: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 5 Class 1 Name\"]=class_b5_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:330: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 5 Class 2 Probability\"]=p_b5_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:331: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 5 Class 2 Name\"]=class_b5_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:332: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 5 Class 3 Probability\"]=p_b5_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:333: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 5 Class 3 Name\"]=class_b5_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:334: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 5 Target Probability\"]=p_target_b5\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:335: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bright 5 Target Name\"]=class_target_b5\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rend Class 1 Probability\"]=p_r_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rend Class 1 Name\"]=class_r_1\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:339: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rend Class 2 Probability\"]=p_r_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:340: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rend Class 2 Name\"]=class_r_2\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:341: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rend Class 3 Probability\"]=p_r_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rend Class 3 Name\"]=class_r_3\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:343: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rend Target Probability\"]=p_target_r\n",
      "/misc/lmbraid19/agnihotr/pruneshift_jupyter/hiwi/utils.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rend Target Name\"]=class_target_r\n"
     ]
    }
   ],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "\n",
    "baseline_path = Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/baselines\")\n",
    "baseline=collect(baseline_path).query(\"Scaling == 1\")\n",
    "\n",
    "std_baseline=baseline.query(\"Network=='resnet18' and not Amda\")\n",
    "add_info(std_baseline)\n",
    "std_baseline.to_csv('csv/baseline_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49511c6f-9ad2-49d5-aa95-c46b24c68803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e7a33-148f-4aa9-a3c2-a3e99bc16a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "\n",
    "baseline_path = Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/baselines\")\n",
    "baseline=collect(baseline_path).query(\"Scaling == 1\")\n",
    "\n",
    "amda_baseline=baseline.query(\"Network=='resnet18' and Amda\")\n",
    "add_info(amda_baseline)\n",
    "amda_baseline.to_csv('csv/baseline_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e4c42-63ce-4be2-b5a6-72e61cfe92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e057b4-4cbc-4927-bb77-33a6ba8e3c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7222fe-2ffd-4463-a1ed-63afc6f8ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "multi_std_base=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/multiheaded/imagenet100\")).query(\"Path=='/misc/lmbraid19/agnihotr/agnihotr-ensemble/multiheaded/imagenet100/standard'\")\n",
    "multi_std_pruned=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/multiheaded/imagenet100/standard/l1_global\"))\n",
    "multi_std=multi_std_base.append(multi_std_pruned)\n",
    "add_info(multi_std)\n",
    "multi_std=multi_std.sort_values(by=\"Model Size\")\n",
    "multi_std[\"Name\"]=[\"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\"]\n",
    "multi_std.to_csv('csv/mutil_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3760e-b5cd-47db-925f-9ebd7c567b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82616213-3322-4a40-b682-b2a7b39eb8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "multi_amda_base=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/multiheaded/imagenet100\")).query(\"Path=='/misc/lmbraid19/agnihotr/agnihotr-ensemble/multiheaded/imagenet100/amda'\")\n",
    "multi_amda_pruned=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/multiheaded/imagenet100/amda/l1_global_actual\"))\n",
    "multi_amda=multi_amda_base.append(multi_amda_pruned)\n",
    "add_info(multi_amda)\n",
    "multi_amda=multi_amda.sort_values(by=\"Model Size\")\n",
    "multi_amda[\"Name\"]=[\"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\"]\n",
    "multi_amda.to_csv('csv/mutil_amda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883415c7-8cab-4d8b-b94a-250d91003721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.lab.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea9641-6b9e-4aaa-93b0-97995fb3ebe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b7181a-06d2-44b9-aa49-f859c67a7c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85229f3b-f949-4eae-b773-82690932362c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fd024-bdc0-4fc2-ba8d-4d2aec271773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b791c6f-edfe-40b6-ae4f-97db7f891904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8ad85-cf20-4608-94c0-d23bb47de851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f70ea-efd4-43aa-bf0e-b7cb94623ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d8f58-653a-4c1f-940b-c8bca38db983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972b9f3-4cfd-4b74-a603-7621a5e68131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import collect, add_info\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c250a1-ab8d-401e-895c-9abb1dd6d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_baseline=pd.read_csv('csv/baseline_std.csv')\n",
    "amda_baseline=pd.read_csv('csv/baseline_amda.csv')\n",
    "multi_std=pd.read_csv('csv/mutil_std.csv')\n",
    "multi_amda=pd.read_csv('csv/mutil_amda.csv')\n",
    "calibrated_pruned_jointly_amda=pd.read_csv('csv/calibrated_pruned_jointly_amda.csv')\n",
    "not_calibrated_pruned_jointly_amda=pd.read_csv('csv/not_calibrated_pruned_jointly_amda.csv')\n",
    "calibrated_pruned_jointly_std=pd.read_csv('csv/calibrated_pruned_jointly_std.csv')\n",
    "not_calibrated_pruned_jointly_std=pd.read_csv('csv/not_calibrated_pruned_jointly_std.csv')\n",
    "calibrated_seperate_amda=pd.read_csv('csv/calibrated_seperate_amda.csv')\n",
    "not_calibrated_seperate_amda=pd.read_csv('csv/not_calibrated_seperate_amda.csv')\n",
    "calibrated_seperate_std=pd.read_csv('csv/calibrated_seperate_std.csv')\n",
    "not_calibrated_seperate_std=pd.read_csv('csv/not_calibrated_seperate_std.csv')\n",
    "not_calibrated_scaled_up_amda=pd.read_csv('csv/scaled_up_amda.csv')\n",
    "not_calibrated_scaled_up_std=pd.read_csv('csv/scaled_up_std.csv')\n",
    "together_amda=pd.read_csv('csv/together_amda.csv')\n",
    "together_std=pd.read_csv('csv/together_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135d77d-ece2-40a6-9528-b6d101bf7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_scaled_up_amda=pd.read_csv('csv/calibrated_scaled_up_amda.csv')\n",
    "calibrated_scaled_up_std=pd.read_csv('csv/calibrated_scaled_up_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d1c9a-fed0-407e-8c70-f2b29bd5759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = not_calibrated_pruned_jointly_std.append(not_calibrated_scaled_up_std, ignore_index=True)\n",
    "std = std.append(not_calibrated_seperate_std, ignore_index=True)\n",
    "std = std.append(together_std, ignore_index=True)\n",
    "std = std.append(multi_std, ignore_index=True)\n",
    "\n",
    "amda = not_calibrated_pruned_jointly_amda.append(not_calibrated_scaled_up_amda, ignore_index=True)\n",
    "amda = amda.append(not_calibrated_seperate_amda, ignore_index=True)\n",
    "amda = amda.append(together_amda, ignore_index=True)\n",
    "amda = amda.append(multi_amda, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7d164-8ad5-449e-a0ac-530428d19026",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_joint_std=calibrated_pruned_jointly_std.append(not_calibrated_pruned_jointly_std, ignore_index=True)\n",
    "prune_joint_amda=calibrated_pruned_jointly_amda.append(not_calibrated_pruned_jointly_amda, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1a5a2-44be-4818-acb9-b756f2e1ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_up_std=calibrated_scaled_up_std.append(not_calibrated_scaled_up_std, ignore_index=True)\n",
    "scaled_up_amda=calibrated_scaled_up_amda.append(not_calibrated_scaled_up_amda, ignore_index=True)\n",
    "\n",
    "seperate_std=calibrated_seperate_std.append(not_calibrated_seperate_std, ignore_index=True)\n",
    "seperate_amda=calibrated_seperate_amda.append(not_calibrated_seperate_amda, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8f6d5-139c-4308-a694-4bb97532faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_joint_std_weight=prune_joint_std[[\"Name\", \"Amda\", \"Model Size\", \"Layer1 Remaining\", \"Layer2 Remaining\", \"Layer3 Remaining\", \"Layer4 Remaining\"]]\n",
    "prune_joint_amda_weight=prune_joint_amda[[\"Name\", \"Amda\", \"Model Size\", \"Layer1 Remaining\", \"Layer2 Remaining\", \"Layer3 Remaining\", \"Layer4 Remaining\"]]\n",
    "prune_joint_std_conf=prune_joint_std[[\"Name\", \"Amda\", \"Model Size\", \"Test Target Probability\", \"Test Target Name\", \"Test Class 1 Probability\", \"Test Class 1 Name\", \"Bright 3 Class 1 Probability\", \"Bright 3 Class 1 Name\"]]\n",
    "prune_joint_amda_conf=prune_joint_amda[[\"Name\", \"Amda\", \"Model Size\", \"Test Target Probability\", \"Test Target Name\", \"Test Class 1 Probability\", \"Test Class 1 Name\", \"Bright 3 Class 1 Probability\", \"Bright 3 Class 1 Name\"]]\n",
    "prune_joint_amda_weight.to_csv('figs/prune_joint_amda_weight.csv')\n",
    "prune_joint_std_weight.to_csv('figs/prune_joint_std_weight.csv')\n",
    "prune_joint_amda_conf.to_csv('figs/prune_joint_amda_conf.csv')\n",
    "prune_joint_std_conf.to_csv('figs/prune_joint_std_conf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e966b-6a38-493d-9ef4-23d21ca786cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_std_weight=multi_std[[\"Name\", \"Amda\", \"Model Size\", \"Layer1 Remaining\", \"Layer2 Remaining\", \"Layer3 Remaining\", \"Layer4 Remaining\"]]\n",
    "multi_amda_weight=multi_amda[[\"Name\", \"Amda\", \"Model Size\", \"Layer1 Remaining\", \"Layer2 Remaining\", \"Layer3 Remaining\", \"Layer4 Remaining\"]]\n",
    "multi_std_conf=multi_std[[\"Name\", \"Amda\", \"Model Size\", \"Test Target Probability\", \"Test Target Name\", \"Test Class 1 Probability\", \"Test Class 1 Name\", \"Bright 3 Class 1 Probability\", \"Bright 3 Class 1 Name\"]]\n",
    "multi_amda_conf=multi_amda[[\"Name\", \"Amda\", \"Model Size\", \"Test Target Probability\", \"Test Target Name\", \"Test Class 1 Probability\", \"Test Class 1 Name\", \"Bright 3 Class 1 Probability\", \"Bright 3 Class 1 Name\"]]\n",
    "multi_amda_weight.to_csv('figs/multi_amda_weight.csv')\n",
    "multi_std_weight.to_csv('figs/multi_std_weight.csv')\n",
    "multi_amda_conf.to_csv('figs/multi_amda_conf.csv')\n",
    "multi_std_conf.to_csv('figs/multi_std_conf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14734e7-5f7c-4a8e-96ca-1393a853eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_std_weight=seperate_std[[\"Name\", \"Amda\", \"Model Size\", \"Layer1 Remaining\", \"Layer2 Remaining\", \"Layer3 Remaining\", \"Layer4 Remaining\"]]\n",
    "seperate_amda_weight=seperate_amda[[\"Name\", \"Amda\", \"Model Size\", \"Layer1 Remaining\", \"Layer2 Remaining\", \"Layer3 Remaining\", \"Layer4 Remaining\"]]\n",
    "seperate_std_conf=seperate_std[[\"Name\", \"Amda\", \"Model Size\", \"Test Target Probability\", \"Test Target Name\", \"Test Class 1 Probability\", \"Test Class 1 Name\", \"Bright 3 Class 1 Probability\", \"Bright 3 Class 1 Name\"]]\n",
    "seperate_amda_conf=seperate_amda[[\"Name\", \"Amda\", \"Model Size\", \"Test Target Probability\", \"Test Target Name\", \"Test Class 1 Probability\", \"Test Class 1 Name\", \"Bright 3 Class 1 Probability\", \"Bright 3 Class 1 Name\"]]\n",
    "seperate_amda_weight.to_csv('figs/seperate_amda_weight.csv')\n",
    "seperate_std_weight.to_csv('figs/seperate_std_weight.csv')\n",
    "seperate_amda_conf.to_csv('figs/seperate_amda_conf.csv')\n",
    "seperate_std_conf.to_csv('figs/seperate_std_conf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bdf83a-e6c9-4d1e-b4e1-e370489501b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_up_std_weight=scaled_up_std[[\"Name\", \"Amda\", \"Model Size\", \"Layer1 Remaining\", \"Layer2 Remaining\", \"Layer3 Remaining\", \"Layer4 Remaining\"]]\n",
    "scaled_up_amda_weight=scaled_up_amda[[\"Name\", \"Amda\", \"Model Size\", \"Layer1 Remaining\", \"Layer2 Remaining\", \"Layer3 Remaining\", \"Layer4 Remaining\"]]\n",
    "scaled_up_std_conf=scaled_up_std[[\"Name\", \"Amda\", \"Model Size\", \"Test Target Probability\", \"Test Target Name\", \"Test Class 1 Probability\", \"Test Class 1 Name\", \"Bright 3 Class 1 Probability\", \"Bright 3 Class 1 Name\"]]\n",
    "scaled_up_amda_conf=scaled_up_amda[[\"Name\", \"Amda\", \"Model Size\", \"Test Target Probability\", \"Test Target Name\", \"Test Class 1 Probability\", \"Test Class 1 Name\", \"Bright 3 Class 1 Probability\", \"Bright 3 Class 1 Name\"]]\n",
    "scaled_up_amda_weight.to_csv('figs/scaled_up_amda_weight.csv')\n",
    "scaled_up_std_weight.to_csv('figs/scaled_up_std_weight.csv')\n",
    "scaled_up_amda_conf.to_csv('figs/scaled_up_amda_conf.csv')\n",
    "scaled_up_std_conf.to_csv('figs/scaled_up_std_conf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac14eb-381c-4b0d-95fc-b62a19867c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17c897-dd26-40b7-a07a-2124ed8a7850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8b2dd-686c-405c-bca7-eb64269df317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ec249-fa08-41ac-84f6-48d6ed4f23be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7701262-d7f1-49ef-a45c-0f9a97861a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ECE\":\"ECE\", \"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in prune_joint_std[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(13.5, 3.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=prune_joint_std, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.35, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"figs/prune_jointly_std.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6588433-c446-4a6a-ac89-437e1c3ca6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ECE\":\"ECE\", \"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in prune_joint_amda[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(13.5, 3.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=prune_joint_amda, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.35, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"figs/prune_jointly_amda.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106d49c-e7e0-4632-9569-9c19923fa900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192837b-789b-4beb-8a29-a87e8663e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ECE\":\"ECE\", \"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in seperate_std[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(13.5, 3.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=seperate_std, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.35, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"figs/seperate_std.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f7e17-5d87-4f3a-8960-2b7b08a96e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ECE\":\"ECE\", \"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in seperate_amda[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(13.5, 3.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=seperate_amda, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.35, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"figs/seperate_amda.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0853d-ec2a-4f9a-8a0c-cbd204ef1dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e1e4c-413a-465c-8cfa-3ef88ac35cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095499d-c0af-4e71-b2cf-1fbfe748c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ECE\":\"ECE\", \"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in scaled_up_std[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(13.5, 3.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=scaled_up_std, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.35, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"figs/scaled_up_std.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c0dee-3ac0-4152-b35d-6bf2c5b313d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ECE\":\"ECE\", \"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in scaled_up_amda[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(13.5, 3.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=scaled_up_amda, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.35, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"figs/scaled_up_amda.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4deecd-73a1-4948-b42d-597ab4d7d1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a822beb-9374-4f16-99bf-bcb8997a4b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27435f-5368-4df5-973a-06058800eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ECE\":\"ECE\", \"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in std[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(13.5, 3.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=std, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        if error == \"ECE\":\n",
    "            ax.set_ylabel(error)\n",
    "        else:\n",
    "            ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.35, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"figs/std_compare.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021bf72-a114-4b36-a8ed-52543e7d5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ECE\":\"ECE\", \"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in amda[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(13.5, 3.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=amda, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        if error == \"ECE\":\n",
    "            ax.set_ylabel(error)\n",
    "        else:\n",
    "            ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.35, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"figs/amda_compare.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2bd71-56d9-4092-9c8a-f89df4cd1287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcede54-8ca8-41c5-8aba-b512ae6141b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490da32e-420e-486b-9db9-55cb3e4f609a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc9cd5-9080-45fb-80b3-802a0a169068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d0ce9-ffe3-41e5-b673-9be4fe18b2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d3a5b-9ec1-4ab2-ac4c-d3afbbbc21cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16186d23-8696-45fc-97a0-503f7730eeea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fc049-2fd8-4a4c-b088-efb4776d6008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6589c44-a637-4a5e-93a8-73f149134b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b621f1-9e4f-45b0-84b7-b4a17dedfc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a3a21-3184-446b-970a-efe5e81e91e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fafb92-6bdb-4652-805b-84472e747de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052aadc6-f9be-4d0c-8cb4-f296fb14b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1eaeef-3733-43f9-80b2-6fe385898ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433efca2-c943-484d-af4b-1b4e2aa24037",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_seperate_amda_base=together.query(\"Path == '/misc/lmbraid19/agnihotr/agnihotr-ensemble/together/imagenet100/amda'\")\n",
    "add_info(together_amda_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49500304-55f9-42fb-86f6-a74dda2d92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_base=together.query(\"Path == '/work/dlclarge1/agnihotr-ensemble/together/imagenet100/standard'\")\n",
    "add_info(together_std_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180b4c3-a696-4c09-a065-bef3bc86d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_l1_local=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/together/imagenet100/amda/l1_channels/\")).query(\"`Prune Method`=='L¹ Filter'\")\n",
    "add_info(together_amda_l1_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c237c08-37da-4694-b498-2ba23a921a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_l1_global=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/together/imagenet100/amda/l1_global/\")).query(\"`Prune Method`=='L¹ Filter Globally'\")\n",
    "add_info(together_amda_l1_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557f928-0915-4a1f-97f1-f64fce56b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_l1_local=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/together/imagenet100/standard/pruned\")).query(\"`Prune Method`=='L¹ Filter'\")\n",
    "together_std_l1_global=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/together/imagenet100/standard/pruned\")).query(\"`Prune Method`=='L¹ Filter Globally'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82d950-8fde-4198-85a7-4c9d4d62ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info(together_std_l1_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad50bb-959b-4dc4-b2dd-897ce33d113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info(together_std_l1_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8d853-9700-4212-a6b4-3897b7fc77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "together=pd.read_csv('together.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e6731-23c7-4d34-902a-3d1c9e69dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_l1_global=together.query(\"`Prune Method`=='L¹ Filter Globally' and Amda\")\n",
    "together_amda_l1_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2d2f5-e29d-42aa-a883-9fe20f280bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_l1_local=together.query(\"`Prune Method`=='L¹ Filter' and Amda\").drop_duplicates(subset=['Model Size'])\n",
    "together_amda_l1_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69259129-4ea0-41be-8ac6-3876e59748ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_l1_global=together.query(\"`Prune Method`=='L¹ Filter Globally' and not Amda\")\n",
    "together_std_l1_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa93cf-53a2-49cc-854a-f0fc347cf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_l1_local=together.query(\"`Prune Method`=='L¹ Filter Globally' and not Amda\")\n",
    "together_std_l1_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e3b16-bbc0-420d-a226-20a0744ef12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_l1_global=together_std_l1_global.append(together_std_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "together_std_l1_global[\"Name\"] = [\"Std L1 global prune ensemble trained together\",\"Std L1 global prune ensemble trained together\",\n",
    "                             \"Std L1 global prune ensemble trained together\", \"Std L1 global prune ensemble trained together\",\n",
    "                             \"Std L1 global prune ensemble trained together\", \"Std L1 global prune ensemble trained together\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9b47b-df79-4e4c-96f2-374bda96e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_std_l1_local=together_std_l1_local.append(together_std_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "together_std_l1_local[\"Name\"] = [\"Std L1 local prune ensemble trained together\",\"Std L1 local prune ensemble trained together\",\n",
    "                             \"Std L1 local prune ensemble trained together\", \"Std L1 local prune ensemble trained together\",\n",
    "                             \"Std L1 local prune ensemble trained together\", \"Std L1 local prune ensemble trained together\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941115d-f41d-4e8d-a426-70cce108e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_l1_local=together_amda_l1_local.append(together_amda_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "together_amda_l1_local[\"Name\"] = [\"Amda L1 local prune ensemble trained together\",\"Amda L1 local prune ensemble trained together\",\n",
    "                             \"Amda L1 local prune ensemble trained together\", \"Amda L1 local prune ensemble trained together\",\n",
    "                             \"Amda L1 local prune ensemble trained together\", \"Amda L1 local prune ensemble trained together\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522cc8f-079e-49c6-8e35-3daaee955f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_amda_l1_global=together_amda_l1_global.append(together_amda_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "together_amda_l1_global[\"Name\"] = [\"Amda L1 global prune ensemble trained together\",\"Amda L1 global prune ensemble trained together\",\n",
    "                             \"Amda L1 global prune ensemble trained together\", \"Amda L1 global prune ensemble trained together\",\n",
    "                             \"Amda L1 global prune ensemble trained together\", \"Amda L1 global prune ensemble trained together\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da84945-0100-449a-8f2e-c959ce7b4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect(Path(\"/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100/amda/pruned\")).sort_values(by=\"Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72def1ef-8f4f-4f66-8704-e668d3fc8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi_amda_base=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100\")).query(\"Path=='/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100/amda'\")\n",
    "#add_info(multi_amda_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1744a5-b8cb-4b26-a225-057f60c6561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_amda_base=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100\")).query(\"Path=='/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100/amda'\")\n",
    "multi_amda_base[\"Model Size\"]=28.117868\n",
    "multi_std_base=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100\")).query(\"Path=='/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100/standard'\")\n",
    "multi_std_base[\"Model Size\"]=28.117868\n",
    "#add_info(multi_std_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d2442-58d6-4827-9fc8-02cc05407645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbfb69-c677-45cc-b3b0-be1b4479cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_std_l1_local=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100/standard/l1_channel\")).sort_values(by=\"Prune Amount\")\n",
    "multi_std_l1_local[\"Model Size\"]=[25.281900, 21.085036, 14.044012, 8.427116, 5.637996, 2.802028]\n",
    "#add_info(multi_std_l1_local)\n",
    "multi_std_l1_local=multi_std_l1_local.append(multi_std_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "multi_std_l1_local[\"Name\"]=[\"Std Multiheaded Ensemble Pruned L1 local\",\"Std Multiheaded Ensemble Pruned L1 local\",\"Std Multiheaded Ensemble Pruned L1 local\",\"Std Multiheaded Ensemble Pruned L1 local\",\"Std Multiheaded Ensemble Pruned L1 local\",\"Std Multiheaded Ensemble Pruned L1 local\",\"Std Multiheaded Ensemble Pruned L1 local\"]\n",
    "multi_std_l1_global=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100/standard/l1_global\")).sort_values(by=\"Prune Amount\")\n",
    "multi_std_l1_global[\"Model Size\"]=[25.319212, 21.082412, 14.057836, 8.429612, 5.611884, 2.802796]\n",
    "#add_info(multi_std_l1_global)\n",
    "multi_std_l1_global=multi_std_l1_global.append(multi_std_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "multi_std_l1_global[\"Name\"]=[\"Std Multiheaded Ensemble Pruned L1 Global\",\"Std Multiheaded Ensemble Pruned L1 Global\",\"Std Multiheaded Ensemble Pruned L1 Global\",\"Std Multiheaded Ensemble Pruned L1 Global\",\"Std Multiheaded Ensemble Pruned L1 Global\",\"Std Multiheaded Ensemble Pruned L1 Global\",\"Std Multiheaded Ensemble Pruned L1 Global\"]\n",
    "\n",
    "\n",
    "multi_amda_l1_local=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100/amda/l1_channel\")).sort_values(by=\"Prune Amount\")\n",
    "multi_amda_l1_local[\"Model Size\"]=[25.281900, 21.085036, 14.044012, 8.427116, 5.637996, 2.802028]\n",
    "#add_info(multi_amda_l1_local)\n",
    "multi_amda_l1_local=multi_amda_l1_local.append(multi_amda_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "multi_amda_l1_local[\"Name\"]=[\"Amda Multiheaded Ensemble Pruned L1 local\",\"Amda Multiheaded Ensemble Pruned L1 local\",\"Amda Multiheaded Ensemble Pruned L1 local\",\"Amda Multiheaded Ensemble Pruned L1 local\",\"Amda Multiheaded Ensemble Pruned L1 local\",\"Amda Multiheaded Ensemble Pruned L1 local\",\"Amda Multiheaded Ensemble Pruned L1 local\"]\n",
    "multi_amda_l1_global=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/multiheaded/imagenet100/amda/l1_global_actual\")).sort_values(by=\"Prune Amount\")\n",
    "multi_amda_l1_global[\"Model Size\"]=[25.306604, 21.092972, 14.053292, 8.425132, 5.620268, 2.818412]\n",
    "#add_info(multi_amda_l1_global)\n",
    "multi_amda_l1_global=multi_amda_l1_global.append(multi_amda_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "multi_amda_l1_global[\"Name\"]=[\"Amda Multiheaded Ensemble Pruned L1 Global\",\"Amda Multiheaded Ensemble Pruned L1 Global\",\"Amda Multiheaded Ensemble Pruned L1 Global\",\"Amda Multiheaded Ensemble Pruned L1 Global\",\"Amda Multiheaded Ensemble Pruned L1 Global\",\"Amda Multiheaded Ensemble Pruned L1 Global\",\"Amda Multiheaded Ensemble Pruned L1 Global\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_scaled_l1_global=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/scaled_resnet18/imagenet100/pruned/l1_global/amda\")).sort_values(by=\"Path\")\n",
    "std_scaled_l1_global=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/scaled_resnet18/imagenet100/pruned/l1_global/standard\")).sort_values(by=\"Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info(std_scaled_l1_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-cheat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info(amda_scaled_l1_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_scaled=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/scaled_resnet18/imagenet100/amda_1.73\")).sort_values(by=\"Path\")\n",
    "standard_scaled=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/scaled_resnet18/imagenet100/standard_1.73\")).sort_values(by=\"Path\")\n",
    "pruned_scaled=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/scaled_resnet18/imagenet100/pruned/l1_local\")).sort_values(by=\"Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info(standard_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info(amda_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info(pruned_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pruned_scaled=pruned_scaled.query(\"not Amda\")\n",
    "std_pruned_scaled = std_pruned_scaled.append(standard_scaled).sort_values(by=\"Model Size\", ascending=False)\n",
    "std_pruned_scaled[\"Name\"] = [\"Std Pruning Scaled Res18\", \"Std Pruning Scaled Res18\", \"Std Pruning Scaled Res18\", \"Std Pruning Scaled Res18\", \"Std Pruning Scaled Res18\", \"Std Pruning Scaled Res18\"]\n",
    "std_pruned_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-facility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaled_l1_global = std_scaled_l1_global.append(standard_scaled).sort_values(by=\"Model Size\", ascending=False)\n",
    "std_scaled_l1_global[\"Name\"] = [\"Std L1 Global Pruning Scaled Res18\", \"Std L1 Global Pruning Scaled Res18\", \"Std L1 Global Pruning Scaled Res18\", \"Std L1 Global Pruning Scaled Res18\", \"Std L1 Global Pruning Scaled Res18\", \"Std L1 Global Pruning Scaled Res18\"]\n",
    "std_scaled_l1_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_pruned_scaled=pruned_scaled.query(\"Amda\")\n",
    "amda_pruned_scaled = amda_pruned_scaled.append(amda_scaled).sort_values(by=\"Model Size\", ascending=False)\n",
    "amda_pruned_scaled[\"Name\"] = [\"Amda Pruning Scaled Res18\", \"Amda Pruning Scaled Res18\", \"Amda Pruning Scaled Res18\", \"Amda Pruning Scaled Res18\", \"Amda Pruning Scaled Res18\", \"Amda Pruning Scaled Res18\"]\n",
    "amda_pruned_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_scaled_l1_global = amda_scaled_l1_global.append(amda_scaled).sort_values(by=\"Model Size\", ascending=False)\n",
    "amda_scaled_l1_global[\"Name\"] = [\"Amda L1 Global Pruning Scaled Res18\", \"Amda L1 Global Pruning Scaled Res18\", \"Amda L1 Global Pruning Scaled Res18\", \"Amda L1 Global Pruning Scaled Res18\", \"Amda L1 Global Pruning Scaled Res18\", \"Amda L1 Global Pruning Scaled Res18\"]\n",
    "amda_scaled_l1_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ensemble=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/performance_ensemble_unpruned\"))\n",
    "#std_ensemble[\"Model Size\"]=33.683436\n",
    "add_info(std_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_ensemble=std_ensemble.copy()\n",
    "amda_ensemble[\"Amda\"]=True\n",
    "amda_ensemble[\"Augmix\"]=True\n",
    "amda_ensemble[\"DeepAugment\"]=True\n",
    "#amda_ensemble[\"Model Size\"]=33.683436\n",
    "amda_ensemble[\"ImageNet100 Error\"]=11.79999709129333\n",
    "amda_ensemble[\"ImageNet100-C Error\"]=25.92933177947998\n",
    "amda_ensemble[\"ImageNet100-R Error\"]=52.0111242995987\n",
    "#add_info(amda_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pruned_sep=collect(Path(\"/misc/lmbraid19/agnihotr/agnihotr-ensemble/train_emsemble/imagenet100/standard/seperated/performance\")).sort_values(by=\"Path\")\n",
    "add_info(std_pruned_sep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pruned_sep=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/seperated/performance\")).sort_values(by=\"Path\")\n",
    "std_pruned_sep[\"Model Size\"]=[30.287340, 25.266156, 16.824300, 10.098924, 3.348972]\n",
    "std_pruned_sep=std_pruned_sep.append(std_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "std_pruned_sep[\"Name\"]=[\"Std Ensemble Pruned Seperate\", \"Std Ensemble Pruned Seperate\", \"Std Ensemble Pruned Seperate\" ,\"Std Ensemble Pruned Seperate\" ,\"Std Ensemble Pruned Seperate\", \"Std Ensemble Pruned Seperate\"]\n",
    "#add_info(std_pruned_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_pruned_sep=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/amda/seperated/performance\")).sort_values(by=\"Path\")\n",
    "amda_pruned_sep[\"Amda\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_pruned_sep[\"Augmix\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_pruned_sep[\"DeepAugment\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_pruned_sep[\"Model Size\"]=[30.287340, 25.266156, 16.824300, 10.098924, 3.348972]\n",
    "amda_pruned_sep=amda_pruned_sep.append(amda_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "amda_pruned_sep[\"Name\"]=[\"Amda Ensemble Pruned Seperate\", \"Amda Ensemble Pruned Seperate\", \"Amda Ensemble Pruned Seperate\" ,\"Amda Ensemble Pruned Seperate\" ,\"Amda Ensemble Pruned Seperate\", \"Amda Ensemble Pruned Seperate\"]\n",
    "#add_info(amda_pruned_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc08765-10af-4174-ab8b-16a2a07185a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_pruned_sep[\"Model Size\"]=[33.683436, 30.287340, 25.266156, 16.824300, 10.098924, 3.348972]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_ensemble_pruned_together=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/amda/together/\")).sort_values(by=\"Prune Amount\")\n",
    "amda_ensemble_pruned_together[\"Model Size\"]=[30.287340, 25.266156, 16.824300, 10.098924, 3.348972]\n",
    "#add_info(amda_ensemble_pruned_together)\n",
    "amda_ensemble_pruned_together=amda_ensemble_pruned_together.append(amda_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "amda_ensemble_pruned_together[\"Name\"]=[\"Amda Ensemble Pruned Together\", \"Amda Ensemble Pruned Together\", \"Amda Ensemble Pruned Together\" ,\"Amda Ensemble Pruned Together\" ,\"Amda Ensemble Pruned Together\", \"Amda Ensemble Pruned Together\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_ensemble_pruned_together=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/together/\")).sort_values(by=\"Prune Amount\")\n",
    "standard_ensemble_pruned_together[\"Model Size\"]=[30.287340, 25.266156, 16.824300, 10.098924, 3.348972]\n",
    "standard_ensemble_pruned_together=standard_ensemble_pruned_together.append(std_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "standard_ensemble_pruned_together[\"Name\"]=[\"Std Ensemble Pruned Together\", \"Std Ensemble Pruned Together\", \"Std Ensemble Pruned Together\" ,\"Std Ensemble Pruned Together\" ,\"Std Ensemble Pruned Together\", \"Std Ensemble Pruned Together\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_info(standard_ensemble_pruned_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amda_ensemble_pruned_together[\"Model Size\"]=[33.683436, 30.287340, 25.266156, 16.824300, 10.098924, 3.348972]\n",
    "#standard_ensemble_pruned_together[\"Model Size\"]=[33.683436, 30.287340, 25.266156, 16.824300, 10.098924, 3.348972]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_l1_global_sep=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/amda/l1_global_seperated/performance\")).sort_values(by=\"Path\")\n",
    "amda_l1_global_sep[\"Amda\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_l1_global_sep[\"Augmix\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_l1_global_sep[\"DeepAugment\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_l1_global_sep[\"Model Size\"]=[30.312364, 25.263468, 16.826348, 10.093164, 3.355948]\n",
    "amda_l1_global_sep=amda_l1_global_sep.append(amda_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "amda_l1_global_sep[\"Name\"]=[\"Amda Ensemble L1 Global\", \"Amda Ensemble L1 Global\", \"Amda Ensemble L1 Global\" ,\"Amda Ensemble L1 Global\" ,\"Amda Ensemble L1 Global\", \"Amda Ensemble L1 Global\"]\n",
    "#add_info(amda_l1_global_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4304ea-a920-4c68-b86c-a9e2de0211d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amda_l1_global_sep[\"Model Size\"]=[33.683436, 30.312364, 25.263468, 16.826348, 10.093164, 3.355948]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_l1_global_sep=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/l1_global_seperated/performance\")).sort_values(by=\"Path\")\n",
    "std_l1_global_sep[\"Amda\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "std_l1_global_sep[\"Augmix\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "std_l1_global_sep[\"DeepAugment\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "std_l1_global_sep[\"Model Size\"]=[30.313004, 25.262892, 16.829996, 10.095532, 3.362220]\n",
    "std_l1_global_sep=std_l1_global_sep.append(std_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "std_l1_global_sep[\"Name\"]=[\"Std Ensemble L1 Global\", \"Std Ensemble L1 Global\", \"Std Ensemble L1 Global\" ,\"Std Ensemble L1 Global\" ,\"Std Ensemble L1 Global\", \"Std Ensemble L1 Global\"]\n",
    "#add_info(std_l1_global_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6527148-c20e-4eff-8dee-913aabcbac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_l1_global_sep=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/l1_global_seperated/performance\")).sort_values(by=\"Path\")\n",
    "#add_info(std_l1_global_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_10 = 30.287340\n",
    "amda_25 = 25.266156\n",
    "amda_50 = 16.824300\n",
    "amda_70 = 10.098924\n",
    "amda_90 = 3.348972\n",
    "std_10 = 30.287340\n",
    "std_25 = 25.266156\n",
    "std_50 = 16.824300\n",
    "std_70 = 10.098924\n",
    "std_90 = 3.348972\n",
    "\n",
    "amda_combine1=28.063724\n",
    "amda_combine2=26.945772\n",
    "amda_combine3=19.642348\n",
    "amda_combine4=24.698092\n",
    "\n",
    "std_combine1=28.063724\n",
    "std_combine2=19.642348\n",
    "std_combine3=23.239660\n",
    "std_combine4=21.779436\n",
    "\n",
    "\n",
    "ran_amda_10=30.287340\n",
    "ran_amda_25=25.266156\n",
    "ran_amda_50=16.824300\n",
    "ran_amda_70=10.098924\n",
    "ran_amda_90=3.348972\n",
    "\n",
    "\n",
    "ran_std_10=30.287340\n",
    "ran_std_25=25.266156\n",
    "ran_std_50=16.824300\n",
    "ran_std_70=10.098924\n",
    "ran_std_90=3.348972\n",
    "\n",
    "amda_l1_global_10=30.312364\n",
    "amda_l1_global_25=25.263468\n",
    "amda_l1_global_50=16.826348\n",
    "amda_l1_global_70=10.093164\n",
    "amda_l1_global_90=3.355948\n",
    "\n",
    "std_l1_global_10=30.313004\n",
    "std_l1_global_25=25.262892\n",
    "std_l1_global_50=16.829996\n",
    "std_l1_global_70=10.095532\n",
    "std_l1_global_90=3.362220\n",
    "\n",
    "\n",
    "amda_combine1=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/amda/prune_randomly/combine1\"))\n",
    "amda_combine1[\"Model Size\"]=28.063724\n",
    "amda_combine1[\"Name\"]=\"Amda_combine_1\"\n",
    "\n",
    "amda_combine2=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/amda/prune_randomly/combine2\"))\n",
    "amda_combine2[\"Model Size\"]=26.945772\n",
    "amda_combine2[\"Name\"]=\"Amda_combine_2\"\n",
    "\n",
    "amda_combine3=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/amda/prune_randomly/combine3\"))\n",
    "amda_combine3[\"Model Size\"]=19.642348\n",
    "amda_combine3[\"Name\"]=\"Amda_combine_3\"\n",
    "\n",
    "amda_combine4=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/amda/prune_randomly/combine4\"))\n",
    "amda_combine4[\"Model Size\"]=24.698092\n",
    "amda_combine4[\"Name\"]=\"Amda_combine_4\"\n",
    "\n",
    "std_combine1=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/prune_randomly/combine1\"))\n",
    "std_combine1[\"Model Size\"]=28.063724\n",
    "std_combine1[\"Name\"]=\"std_combine_1\"\n",
    "\n",
    "std_combine2=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/prune_randomly/combine2\"))\n",
    "std_combine2[\"Model Size\"]=19.642348\n",
    "std_combine2[\"Name\"]=\"std_combine_2\"\n",
    "\n",
    "std_combine3=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/prune_randomly/combine3\"))\n",
    "std_combine3[\"Model Size\"]=23.239660\n",
    "std_combine3[\"Name\"]=\"std_combine_3\"\n",
    "\n",
    "std_combine4=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/prune_randomly/combine4\"))\n",
    "std_combine4[\"Model Size\"]=21.779436\n",
    "std_combine4[\"Name\"]=\"std_combine_4\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "amda_pruned_ran=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/amda/random_channel_seperate/performance\")).sort_values(by=\"Path\")\n",
    "amda_pruned_ran[\"Amda\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_pruned_ran[\"Augmix\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_pruned_ran[\"DeepAugment\"]=[\"True\", \"True\", \"True\", \"True\", \"True\"]\n",
    "amda_pruned_ran[\"Model Size\"]=[30.287340, 25.266156, 16.824300, 10.098924, 3.348972]\n",
    "amda_pruned_ran=amda_pruned_ran.append(amda_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "amda_pruned_ran[\"Name\"]=[\"Amda Ensemble Random Pruning\", \"Amda Ensemble Random Pruning\", \"Amda Ensemble Random Pruning\" ,\"Amda Ensemble Random Pruning\" ,\"Amda Ensemble Random Pruning\", \"Amda Ensemble Random Pruning\"]\n",
    "\n",
    "\n",
    "\n",
    "std_pruned_ran=collect(Path(\"/work/dlclarge1/agnihotr-ensemble/train_emsemble/imagenet100/standard/random_channel_seperate/performance\")).sort_values(by=\"Path\")\n",
    "std_pruned_ran[\"Model Size\"]=[30.287340, 25.266156, 16.824300, 10.098924, 3.348972]\n",
    "std_pruned_ran=std_pruned_ran.append(std_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "std_pruned_ran[\"Name\"]=[\"Standard Ensemble Random Pruning\", \"Standard Ensemble Random Pruning\", \"Standard Ensemble Random Pruning\" ,\"Standard Ensemble Random Pruning\" ,\"Standard Ensemble Random Pruning\", \"Standard Ensemble Random Pruning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amda_pruned_ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_pruned_ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_path = Path(\"/work/dlclarge2/agnihotr-shashank-pruneshift/hoffmaja-pruneshift/experiments/img100/workshop/baselines\")\n",
    "baseline=collect(baseline_path).query(\"Scaling == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_baseline=baseline.query(\"Network=='resnet18' and not Amda\")\n",
    "add_info(std_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_baseline=baseline.query(\"Network=='resnet18' and Amda\")\n",
    "add_info(amda_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [\"ImageNet100 Error\", \"ImageNet100-C Error\", \"ImageNet100-R Error\"]\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec51125-bc34-4b7d-9d31-1f154e63a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_compare_multihead=multi_std_l1_local.append(multi_std_l1_global, ignore_index=True)\n",
    "amda_compare_multihead=multi_amda_l1_local.append(multi_amda_l1_global, ignore_index=True)\n",
    "std_compare_together=together_std_l1_local.append(together_std_l1_global, ignore_index=True)\n",
    "amda_compare_together=together_amda_l1_local.append(together_amda_l1_global, ignore_index=True)\n",
    "std_compare_scaled=std_pruned_scaled.append(std_scaled_l1_global, ignore_index=True)\n",
    "amda_compare_scaled=amda_pruned_scaled.append(amda_scaled_l1_global, ignore_index=True)\n",
    "std_compare_sep=std_pruned_sep.append(std_l1_global_sep, ignore_index=True)\n",
    "amda_compare_sep=amda_pruned_sep.append(amda_l1_global_sep, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c0baa-c38d-4644-aa5f-54425f009e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in std_compare_multihead[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=std_compare_multihead, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"standard_compare_multiheaded.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738f654-ba65-4058-b029-6e89d0348fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in std_compare_together[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=std_compare_together, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"standard_compare_ensemble_together.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc505bc9-a609-4e6d-a695-509829d3b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in std_compare_scaled[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=std_compare_scaled, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"standard_compare_scaled_up_resnet18.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c80bf-a831-4abd-a338-a26636266dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in std_compare_sep[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=std_compare_sep, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"standard_compare_seperated_ensemble_3_resnet18.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097bcb21-cefd-4867-8589-a08a8c5db2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b8eb5-c429-4c98-afd0-2e53475cd984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb1099-baa1-4bb0-8164-e6b8a11442f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f655216-4dc8-4dc0-9805-df68fbcc3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in amda_compare_multihead[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=amda_compare_multihead, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"AMDA_compare_multiheaded.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ddbc0-9721-45d9-9193-38f7270a6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in amda_compare_together[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=amda_compare_together, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"AMDA_compare_ensemble_together.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f30c6d9-653a-4757-a0ae-6591180db6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in amda_compare_scaled[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=amda_compare_scaled, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"AMDA_compare_scaled_up_resnet18.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a127d83-62ac-495d-9f3a-c58450cc032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in amda_compare_sep[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=amda_compare_sep, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.15), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"AMDA_compare_seperated_ensemble_3_resnet18.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8c1b4-b55c-4df8-8692-e6b626d18eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b2b7b-496f-4fca-a8e8-ec3ca20e2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_amda_base_path=Path(\"/work/dlclarge1/agnihotr-ensemble/kd_amda_ensemble/unpruned/performance\")\n",
    "kd_amda_pruned_path=[Path(\"/work/dlclarge1/agnihotr-ensemble/kd_amda_ensemble/pruned/10/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/kd_amda_ensemble/pruned/25/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/kd_amda_ensemble/pruned/50/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/kd_amda_ensemble/pruned/70/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/kd_amda_ensemble/pruned/90/performance\")]\n",
    "kd_amda_base=collect(kd_amda_base_path)\n",
    "kd_amda_base[\"Model Size\"]=[33.683436]\n",
    "kd_amda_pruned=collect(*kd_amda_pruned_path).sort_values(by=\"Path\")\n",
    "kd_amda_pruned[\"Model Size\"]=[30.314924, 25.255788, 16.839020, 10.088428, 3.355500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65e625-19ff-4b85-8e92-7e76ac9c8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_amda_pruned=kd_amda_pruned.append(kd_amda_base).sort_values(by=\"Model Size\", ascending=False)\n",
    "kd_amda_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae28b6-0670-42dd-a104-4620ec3c4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_std_l1_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf069dcd-d2c5-46a7-9259-47606a3876d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_amda_pruned[\"Model Size\"]=[33.683436, 30.314924, 25.255788, 16.839020, 10.088428, 3.355500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba1fdf-3823-4af4-978f-265c4ed24eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_prune_join_train_sep_path=[Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/amda/10/finetune/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/amda/25/finetune/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/amda/50/finetune/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/amda/70/finetune/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/amda/90/finetune/performance\"),]\n",
    "amda_prune_join_train_sep=collect(*amda_prune_join_train_sep_path).sort_values(by=\"Path\")\n",
    "amda_prune_join_train_sep[\"Model Size\"]=[30.308908, 25.251948, 16.827180, 10.093164, 3.349100]\n",
    "amda_prune_join_train_sep=amda_prune_join_train_sep.append(amda_ensemble).sort_values(by=\"Model Size\", ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "std_prune_join_train_sep_path=[Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/standard/10/finetune/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/standard/25/finetune/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/standard/50/finetune/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/standard/70/finetune/performance\"),\n",
    "                Path(\"/work/dlclarge1/agnihotr-ensemble/prune_joint_train_sep/img100/standard/90/finetune/performance\"),]\n",
    "std_prune_join_train_sep=collect(*std_prune_join_train_sep_path).sort_values(by=\"Path\")\n",
    "std_prune_join_train_sep[\"Model Size\"]=[30.315308, 25.265196, 16.832300, 10.091500, 3.354988]\n",
    "std_prune_join_train_sep=std_prune_join_train_sep.append(std_ensemble).sort_values(by=\"Model Size\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550b209-2622-4c13-83c5-9207bba2d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_std_l1_global[\"Name\"]=[\"Multiheaded Ensemble\",\"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\"]\n",
    "together_std_l1_global[\"Name\"]=[\"Ensemble trained jointly\", \"Ensemble trained jointly\", \"Ensemble trained jointly\", \"Ensemble trained jointly\", \"Ensemble trained jointly\", \"Ensemble trained jointly\"]\n",
    "std_scaled_l1_global[\"Name\"]=[\"Scaled-up ResNet18\", \"Scaled-up ResNet18\", \"Scaled-up ResNet18\", \"Scaled-up ResNet18\", \"Scaled-up ResNet18\", \"Scaled-up ResNet18\"]\n",
    "std_l1_global_sep[\"Name\"]=[\"Ensemble trained seperately\", \"Ensemble trained seperately\", \"Ensemble trained seperately\", \"Ensemble trained seperately\", \"Ensemble trained seperately\", \"Ensemble trained seperately\"]\n",
    "std_prune_join_train_sep[\"Name\"]=[\"Ensemble trained seperately pruned jointly\", \"Ensemble trained seperately pruned jointly\",\"Ensemble trained seperately pruned jointly\",\"Ensemble trained seperately pruned jointly\",\"Ensemble trained seperately pruned jointly\",\"Ensemble trained seperately pruned jointly\"]\n",
    "\n",
    "multi_amda_l1_global[\"Name\"]=[\"Multiheaded Ensemble\",\"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\", \"Multiheaded Ensemble\"]\n",
    "together_amda_l1_global[\"Name\"]=[\"Ensemble trained jointly\", \"Ensemble trained jointly\", \"Ensemble trained jointly\", \"Ensemble trained jointly\", \"Ensemble trained jointly\", \"Ensemble trained jointly\"]\n",
    "amda_scaled_l1_global[\"Name\"]=[\"Scaled-up ResNet18\", \"Scaled-up ResNet18\", \"Scaled-up ResNet18\", \"Scaled-up ResNet18\", \"Scaled-up ResNet18\", \"Scaled-up ResNet18\"]\n",
    "amda_l1_global_sep[\"Name\"]=[\"Ensemble trained seperately\", \"Ensemble trained seperately\", \"Ensemble trained seperately\", \"Ensemble trained seperately\", \"Ensemble trained seperately\", \"Ensemble trained seperately\"]\n",
    "amda_prune_join_train_sep[\"Name\"]=[\"Ensemble trained seperately pruned jointly\", \"Ensemble trained seperately pruned jointly\",\"Ensemble trained seperately pruned jointly\",\"Ensemble trained seperately pruned jointly\",\"Ensemble trained seperately pruned jointly\",\"Ensemble trained seperately pruned jointly\"]\n",
    "kd_amda_pruned[\"Name\"]=[\"Ensemble trained seperately + KD\", \"Ensemble trained seperately + KD\", \"Ensemble trained seperately + KD\", \"Ensemble trained seperately + KD\", \"Ensemble trained seperately + KD\", \"Ensemble trained seperately + KD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ba1c2-bd71-4da5-9387-0efd103874b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_compare_methods=multi_std_l1_global.append(together_std_l1_global, ignore_index=True)\n",
    "std_compare_methods=std_compare_methods.append(std_scaled_l1_global, ignore_index=True)\n",
    "std_compare_methods=std_compare_methods.append(std_l1_global_sep, ignore_index=True)\n",
    "std_compare_methods=std_compare_methods.append(std_prune_join_train_sep, ignore_index=True)\n",
    "#std_compare_methods=std_compare_methods.append(std_pruned_ran, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec89012-4ba1-48a2-b43e-e70f3e77756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_compare_methods=multi_amda_l1_global.append(together_amda_l1_global, ignore_index=True)\n",
    "amda_compare_methods=amda_compare_methods.append(amda_scaled_l1_global, ignore_index=True)\n",
    "amda_compare_methods=amda_compare_methods.append(amda_l1_global_sep, ignore_index=True)\n",
    "#amda_compare_methods=amda_compare_methods.append(kd_amda_pruned, ignore_index=True)\n",
    "amda_compare_methods=amda_compare_methods.append(amda_prune_join_train_sep, ignore_index=True)\n",
    "#amda_compare_methods=amda_compare_methods.append(amda_pruned_ran, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecaf38-981f-4888-b492-5f8345b85ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amda_compare_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae39419-696f-4d5c-afd1-9bfedaf44b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_compare_methods2=amda_scaled_l1_global.append(kd_amda_pruned, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc1a01-c624-45f7-b87e-eef7c871e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in std_compare_methods[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=std_compare_methods, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.15, 1.2), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"standard_compare_methods.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb9e907-dce9-4290-93b5-be5adcc7b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in amda_compare_methods[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=amda_compare_methods, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.2), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"AMDA_compare_methods.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f3394-e2d2-4cef-8992-4fc0f41ebe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in amda_compare_methods2[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "\n",
    "        sns.lineplot(data=amda_compare_methods2, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]        \n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    #fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.25, 1.2), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"AMDA_compare_methods_2.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e9466-6d66-43ec-b99c-80cfcfbcbbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4664a1-97a6-43ce-a628-d083871bee78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e8e7e-40b4-4610-8a2e-15d58e8d9926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df=std_pruned_scaled.append(std_pruned_sep)\n",
    "std_df=std_df.append(standard_ensemble_pruned_together)\n",
    "std_df=std_df.append(std_pruned_ran)\n",
    "std_df=std_df.append(std_l1_global_sep)\n",
    "std_df=std_df.append(std_scaled_l1_global)\n",
    "std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_combine1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "amda_df=amda_pruned_scaled.append(amda_pruned_sep)\n",
    "amda_df=amda_df.append(amda_ensemble_pruned_together)\n",
    "amda_df=amda_df.append(amda_pruned_ran)\n",
    "amda_df=amda_df.append(amda_l1_global_sep)\n",
    "amda_df=amda_df.append(amda_scaled_l1_global)\n",
    "amda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in std_df[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "        sns.lineplot(data=std_df, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = std_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "        c1y, c1x = std_combine1.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "        c2y, c2x = std_combine2.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "        c3y, c3x = std_combine3.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "        c4y, c4x = std_combine4.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "\n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "        ax.scatter(c1x, c1y, marker='.', color='blue', label='Random Combination 1', zorder=19)\n",
    "        ax.scatter(c2x, c2y, marker='.', color='green', label='Random Combination 2', zorder=19)\n",
    "        ax.scatter(c3x, c3y, marker='.', color='orange', label='Random Combination 3', zorder=19)\n",
    "        ax.scatter(c4x, c4y, marker='.', color='purple', label='Random Combination 4', zorder=20)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"standard.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ERROR_LABELS = {\"ImageNet100 Error\": \"ImageNet100\", \"ImageNet100-C Error\": \"ImageNet100-C\", \"ImageNet100-R Error\": \"ImageNet100-R\"}\n",
    "for network in amda_df[\"Network\"].unique():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15.5, 5.5))\n",
    "    for (error, label), ax in zip(ERROR_LABELS.items(), axes.flatten()):\n",
    "        sns.lineplot(data=amda_df, x=\"Model Size\", y=error , hue=\"Name\", ax=ax, marker=\"s\", style=\"Name\")\n",
    "\n",
    "        y, x = amda_baseline.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "        c1y, c1x = amda_combine1.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "        c2y, c2x = amda_combine2.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "        c3y, c3x = amda_combine3.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "        c4y, c4x = amda_combine4.query(f\"Network == '{network}'\")[[error, \"Model Size\"]].to_numpy()[0]\n",
    "\n",
    "        ax.scatter(x, y, marker='x', color='black', label='Original Model', zorder=19)\n",
    "        ax.scatter(c1x, c1y, marker='.', color='blue', label='Random Combination 1', zorder=19)\n",
    "        ax.scatter(c2x, c2y, marker='.', color='green', label='Random Combination 2', zorder=19)\n",
    "        ax.scatter(c3x, c3y, marker='.', color='orange', label='Random Combination 3', zorder=19)\n",
    "        ax.scatter(c4x, c4y, marker='.', color='purple', label='Random Combination 4', zorder=19)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend('', frameon=False)\n",
    "        ax.set_title(label)\n",
    "        ax.set_ylabel(error + \" (%)\" )\n",
    "        ax.set_xlabel(\"Num. of Parameters (millions)\")\n",
    "\n",
    "    \n",
    "    fig.legend(handles[:-1], labels[:-1], bbox_to_anchor=(0.25, 1.3), loc=2, borderaxespad=0., ncol=2)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(\"amda.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-wildlife",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-enclosure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=torch.load(\"/work/dlclarge1/agnihotr-ensemble/debug/debug8/network1.layer1.0.conv1.weight_mask.pt\")\n",
    "net2=torch.load(\"/work/dlclarge1/agnihotr-ensemble/debug/debug8/network2.layer1.0.conv1.weight_mask.pt\")\n",
    "net3=torch.load(\"/work/dlclarge1/agnihotr-ensemble/debug/debug8/network3.layer1.0.conv1.weight_mask.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=torch.load(\"/work/dlclarge1/agnihotr-ensemble/debug/debug8/network1.layer1.0.conv1.weight_mask.pt\")\n",
    "net2=torch.load(\"/work/dlclarge1/agnihotr-ensemble/debug/debug8/network2.layer1.0.conv1.weight_mask.pt\")\n",
    "net3=torch.load(\"/work/dlclarge1/agnihotr-ensemble/debug/debug8/network3.layer1.0.conv1.weight_mask.pt\")\n",
    "\n",
    "title=\"layer1.0.conv1.weight_mask\"\n",
    "fig, axes = plt.subplots(1, 1, figsize=(15.5, 5.5))\n",
    "for net, lb in zip([net1,net2,net3], [\"network1\", \"network2\", \"network3\"]):\n",
    "    plt.plot(net.flatten(), label=lb)\n",
    "    plt.legend(loc=2, borderaxespad=0., ncol=3, bbox_to_anchor=(0.3, 1.2))\n",
    "plt.tight_layout()\n",
    "plt.title(title)\n",
    "plt.ylabel(\"Mask 1 or 0\")\n",
    "plt.xlabel(\"Flattened mask tensor\")\n",
    "path='masks/'+title+'.png'\n",
    "plt.savefig(path, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(net1.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(net2.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(net3.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-chambers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa025e7-6717-4f7e-a068-9fff125e5118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
